{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc843f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== crit1 ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        34\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.45      0.50      0.47        38\n",
      "weighted avg       0.80      0.89      0.85        38\n",
      "\n",
      "\n",
      "==== crit2 ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        37\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.97        38\n",
      "   macro avg       0.49      0.50      0.49        38\n",
      "weighted avg       0.95      0.97      0.96        38\n",
      "\n",
      "\n",
      "==== crit3 ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.13      0.24        15\n",
      "           1       0.64      1.00      0.78        23\n",
      "\n",
      "    accuracy                           0.66        38\n",
      "   macro avg       0.82      0.57      0.51        38\n",
      "weighted avg       0.78      0.66      0.56        38\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\workbook\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\workbook\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\workbook\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\workbook\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\workbook\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\workbook\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv(\"teacher_feedback_examples_ru.csv\", sep=\";\", encoding=\"cp1251\")\n",
    "\n",
    "X = df[\"comment\"]\n",
    "Y = df[[\"crit1\",\"crit2\",\"crit3\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    max_features=5000\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "for col in [\"crit1\",\"crit2\",\"crit3\"]:\n",
    "    print(\"\\n====\", col, \"====\")\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train_vec, y_train[col])\n",
    "\n",
    "    preds = clf.predict(X_test_vec)\n",
    "    print(classification_report(y_test[col], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa90e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184                             Выйди и зайди нормально!\n",
      "163                   Как ты не понимаешь! Я же понимаю!\n",
      "18                                    Ты на верном пути!\n",
      "15                                         Замечательно!\n",
      "67                                          Так держать!\n",
      "108                   Я никогда не видел ничего лучшего.\n",
      "45                                     Это то, что надо!\n",
      "76                                           Наконец-то!\n",
      "16                                    Прекрасное начало!\n",
      "132    Ты что, действительно такой умный? - Кто, я? -...\n",
      "Name: comment, dtype: str\n"
     ]
    }
   ],
   "source": [
    "wrong = X_test[y_test[\"crit1\"] != preds]\n",
    "print(wrong.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6a4256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87        15\n",
      "           1       0.91      0.91      0.91        23\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.89      0.89      0.89        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv(\"teacher_feedback_examples_ru.csv\", sep=\";\", encoding=\"cp1251\")\n",
    "\n",
    "X = df[\"comment\"]\n",
    "y = df[\"crit3\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    max_features=5000\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "preds = clf.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58659770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supportive:\n",
      "[(np.float64(0.33588394534359955), 'молодец'), (np.float64(0.33588394534359955), 'необыкновенно'), (np.float64(0.33588394534359955), 'отлично'), (np.float64(0.33588394534359955), 'поражен'), (np.float64(0.33588394534359955), 'потрясающе'), (np.float64(0.33588394534359955), 'правильно'), (np.float64(0.33588394534359955), 'сенсационно'), (np.float64(0.33588394534359955), 'совершенно'), (np.float64(0.33588394534359955), 'талантливо'), (np.float64(0.33588394534359955), 'фантастика'), (np.float64(0.3516614439570385), 'работу'), (np.float64(0.37690597702943657), 'горжусь'), (np.float64(0.3898325276933381), 'тобой'), (np.float64(0.3930998205739018), 'очень'), (np.float64(0.4009899176645982), 'значительно'), (np.float64(0.4616283700611946), 'лучше'), (np.float64(0.5783011902940383), 'великолепно'), (np.float64(0.5998790687192113), 'ты'), (np.float64(0.726542121046756), 'хорошо'), (np.float64(1.3966477936366029), 'это')]\n",
      "Non-supportive:\n",
      "[(np.float64(-0.7188706553813826), 'чем'), (np.float64(-0.6552687244618413), 'на'), (np.float64(-0.5300425360846356), 'что'), (np.float64(-0.4945293402931455), 'вы'), (np.float64(-0.4351072056014204), 'лучше чем'), (np.float64(-0.3934290893849867), 'не'), (np.float64(-0.36259990387219637), 'пока'), (np.float64(-0.3596626942644383), 'классе'), (np.float64(-0.34311994443345406), 'так так'), (np.float64(-0.33321874299430426), 'если'), (np.float64(-0.3215423042567007), 'одни'), (np.float64(-0.31936282622285056), 'школу'), (np.float64(-0.2897410705291647), 'то'), (np.float64(-0.28665267718143755), 'объявление'), (np.float64(-0.28665267718143755), 'объявляю'), (np.float64(-0.28665267718143755), 'объявляю объявление'), (np.float64(-0.28337686361012726), 'неузнаваем'), (np.float64(-0.28337686361012726), 'неузнаваем сегодня'), (np.float64(-0.28337686361012726), 'ты неузнаваем'), (np.float64(-0.27901612136143356), 'двойку')]\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefs = clf.coef_[0]\n",
    "\n",
    "top_pos = sorted(zip(coefs, feature_names))[-20:]\n",
    "top_neg = sorted(zip(coefs, feature_names))[:20]\n",
    "\n",
    "print(\"Supportive:\")\n",
    "print(top_pos)\n",
    "\n",
    "print(\"Non-supportive:\")\n",
    "print(top_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ce1b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163                   Как ты не понимаешь! Я же понимаю!\n",
      "18                                    Ты на верном пути!\n",
      "15                                         Замечательно!\n",
      "67                                          Так держать!\n",
      "108                   Я никогда не видел ничего лучшего.\n",
      "45                                     Это то, что надо!\n",
      "76                                           Наконец-то!\n",
      "16                                    Прекрасное начало!\n",
      "132    Ты что, действительно такой умный? - Кто, я? -...\n",
      "60                                          Превосходно!\n",
      "Name: comment, dtype: str\n"
     ]
    }
   ],
   "source": [
    "wrong = X_test[y_test[\"crit2\"] != preds]\n",
    "print(wrong.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "799e0ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184                             Выйди и зайди нормально!\n",
      "163                   Как ты не понимаешь! Я же понимаю!\n",
      "76                                           Наконец-то!\n",
      "132    Ты что, действительно такой умный? - Кто, я? -...\n",
      "115                            Вот этого я еще не видел.\n",
      "152             Я завтра неожиданно дам вам контрольную.\n",
      "137                   Здесь и так душно, а еще вы орете!\n",
      "187                  Сейчас рассажу эту сладкую парочку!\n",
      "150              Ты весь урок смотришь на меня затылком.\n",
      "167                 Скажи всем, мы все вместе посмеемся!\n",
      "Name: comment, dtype: str\n"
     ]
    }
   ],
   "source": [
    "wrong = X_test[y_test[\"crit3\"] != preds]\n",
    "print(wrong.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "791029b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg_balanced  F1 mean=0.842 std=0.018\n",
      "LinearSVC        F1 mean=0.835 std=0.015\n",
      "ComplementNB     F1 mean=0.749 std=0.053\n",
      "RandomForest     F1 mean=0.768 std=0.013\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "df = pd.read_csv(\"teacher_feedback_examples_ru.csv\", sep=\";\", encoding=\"cp1251\")\n",
    "X = df[\"comment\"].astype(str)\n",
    "y = df[\"crit3\"].astype(int)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"LogReg_balanced\": LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
    "    \"LinearSVC\": LinearSVC(class_weight=\"balanced\"),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    # Деревья: часто хуже на TF-IDF, но попробуем, чтобы закрыть запрос консультанта\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=500, random_state=42),\n",
    "    # бустинг по деревьям, который умеет работать с разреженными (HistGB — на dense; тут может быть ограничение)\n",
    "}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), max_features=5000)),\n",
    "        (\"clf\", clf),\n",
    "    ])\n",
    "    scores = cross_val_score(pipe, X, y, cv=cv, scoring=\"f1\")\n",
    "    print(f\"{name:16s} F1 mean={scores.mean():.3f} std={scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f87334e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogReg_balanced</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  F1_mean  F1_std\n",
       "0  LogReg_balanced    0.842   0.018\n",
       "1        LinearSVC    0.835   0.015\n",
       "3     RandomForest    0.768   0.013\n",
       "2     ComplementNB    0.749   0.053"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = {\n",
    "    \"Model\": [\"LogReg_balanced\", \"LinearSVC\", \"ComplementNB\", \"RandomForest\"],\n",
    "    \"F1_mean\": [0.842, 0.835, 0.749, 0.768],\n",
    "    \"F1_std\": [0.018, 0.015, 0.053, 0.013]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(\"F1_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c2417",
   "metadata": {},
   "source": [
    "### Results\n",
    "We evaluated several classical classifiers using 5-fold stratified cross-validation on the annotated corpus (n ≈ 189).\n",
    "The best performance was achieved by TF-IDF features combined with Logistic Regression (F1 = 0.84 ± 0.02). LinearSVC showed comparable results (F1 = 0.83 ± 0.02), while tree-based models (Random Forest) and Naive Bayes underperformed. The low standard deviation across folds indicates stable performance despite the relatively small dataset. Due to extreme class imbalance and insufficient positive instances, criteria 1 and 2 were excluded from reliable modeling. Only supportive tone (criterion 3) demonstrated consistent learnable signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d378d085",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The experiment demonstrates that supportive tone in teacher feedback can be reliably detected using surface lexical features, even in a relatively small dataset.\n",
    "Linear models outperform tree-based methods for TF-IDF text representations. The results confirm that affective and evaluative lexical markers provide strong predictive signal. Future work may include expanding the dataset and exploring contextual embeddings; however, classical models already provide robust baseline performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
